{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: bitsandbytes==0.43.0 in ./miniconda3/lib/python3.12/site-packages (0.43.0)\n",
      "Requirement already satisfied: torch in ./miniconda3/lib/python3.12/site-packages (from bitsandbytes==0.43.0) (2.3.0+cu121)\n",
      "Requirement already satisfied: numpy in ./miniconda3/lib/python3.12/site-packages (from bitsandbytes==0.43.0) (1.26.4)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (4.12.1)\n",
      "Requirement already satisfied: sympy in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (1.12.1)\n",
      "Requirement already satisfied: networkx in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.43.0) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.12/site-packages (from jinja2->torch->bitsandbytes==0.43.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./miniconda3/lib/python3.12/site-packages (from sympy->torch->bitsandbytes==0.43.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: datasets==2.10.1 in ./miniconda3/lib/python3.12/site-packages (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (0.3.6)\n",
      "Requirement already satisfied: pandas in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (4.66.2)\n",
      "Requirement already satisfied: xxhash in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in ./miniconda3/lib/python3.12/site-packages (from fsspec[http]>=2021.11.1->datasets==2.10.1) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (0.23.3)\n",
      "Requirement already satisfied: packaging in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniconda3/lib/python3.12/site-packages (from datasets==2.10.1) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./miniconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.10.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./miniconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.10.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./miniconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.10.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./miniconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.10.1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./miniconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.10.1) (1.9.4)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.10.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.10.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.10.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.10.1) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./miniconda3/lib/python3.12/site-packages (from pandas->datasets==2.10.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniconda3/lib/python3.12/site-packages (from pandas->datasets==2.10.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./miniconda3/lib/python3.12/site-packages (from pandas->datasets==2.10.1) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.10.1) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: transformers==4.38.2 in ./miniconda3/lib/python3.12/site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.12/site-packages (from transformers==4.38.2) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./miniconda3/lib/python3.12/site-packages (from transformers==4.38.2) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/lib/python3.12/site-packages (from transformers==4.38.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.12/site-packages (from transformers==4.38.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniconda3/lib/python3.12/site-packages (from transformers==4.38.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniconda3/lib/python3.12/site-packages (from transformers==4.38.2) (2024.5.15)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.12/site-packages (from transformers==4.38.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./miniconda3/lib/python3.12/site-packages (from transformers==4.38.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./miniconda3/lib/python3.12/site-packages (from transformers==4.38.2) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./miniconda3/lib/python3.12/site-packages (from transformers==4.38.2) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers==4.38.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers==4.38.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers==4.38.2) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers==4.38.2) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: peft==0.9.0 in ./miniconda3/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/lib/python3.12/site-packages (from peft==0.9.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.12/site-packages (from peft==0.9.0) (23.2)\n",
      "Requirement already satisfied: psutil in ./miniconda3/lib/python3.12/site-packages (from peft==0.9.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in ./miniconda3/lib/python3.12/site-packages (from peft==0.9.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./miniconda3/lib/python3.12/site-packages (from peft==0.9.0) (2.3.0+cu121)\n",
      "Requirement already satisfied: transformers in ./miniconda3/lib/python3.12/site-packages (from peft==0.9.0) (4.38.2)\n",
      "Requirement already satisfied: tqdm in ./miniconda3/lib/python3.12/site-packages (from peft==0.9.0) (4.66.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./miniconda3/lib/python3.12/site-packages (from peft==0.9.0) (0.28.0)\n",
      "Requirement already satisfied: safetensors in ./miniconda3/lib/python3.12/site-packages (from peft==0.9.0) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in ./miniconda3/lib/python3.12/site-packages (from peft==0.9.0) (0.23.3)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (2024.2.0)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (4.12.1)\n",
      "Requirement already satisfied: sympy in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (1.12.1)\n",
      "Requirement already satisfied: networkx in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.9.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.9.0) (12.5.40)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniconda3/lib/python3.12/site-packages (from transformers->peft==0.9.0) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./miniconda3/lib/python3.12/site-packages (from transformers->peft==0.9.0) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft==0.9.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./miniconda3/lib/python3.12/site-packages (from sympy->torch>=1.13.0->peft==0.9.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: sentencepiece==0.1.99 in ./miniconda3/lib/python3.12/site-packages (0.1.99)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: accelerate==0.28.0 in ./miniconda3/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/lib/python3.12/site-packages (from accelerate==0.28.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.12/site-packages (from accelerate==0.28.0) (23.2)\n",
      "Requirement already satisfied: psutil in ./miniconda3/lib/python3.12/site-packages (from accelerate==0.28.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in ./miniconda3/lib/python3.12/site-packages (from accelerate==0.28.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./miniconda3/lib/python3.12/site-packages (from accelerate==0.28.0) (2.3.0+cu121)\n",
      "Requirement already satisfied: huggingface-hub in ./miniconda3/lib/python3.12/site-packages (from accelerate==0.28.0) (0.23.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./miniconda3/lib/python3.12/site-packages (from accelerate==0.28.0) (0.4.3)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (4.12.1)\n",
      "Requirement already satisfied: sympy in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (1.12.1)\n",
      "Requirement already satisfied: networkx in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.28.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.28.0) (12.5.40)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub->accelerate==0.28.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub->accelerate==0.28.0) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate==0.28.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./miniconda3/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate==0.28.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: colorama==0.4.6 in ./miniconda3/lib/python3.12/site-packages (0.4.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes==0.43.0\n",
    "!pip install datasets==2.10.1\n",
    "!pip install transformers==4.38.2\n",
    "!pip install peft==0.9.0\n",
    "!pip install sentencepiece==0.1.99\n",
    "!pip install -U accelerate==0.28.0\n",
    "!pip install colorama==0.4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "import warnings\n",
    "import logging\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import PeftModel\n",
    "from colorama import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, BitsAndBytesConfig,DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "\n",
    "from transformers import GenerationConfig\n",
    "from peft import (\n",
    "    prepare_model_for_int8_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_kbit_training,\n",
    "    TaskType\n",
    ")\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'response_total', 'response'],\n",
       "    num_rows: 37123\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.load_from_disk('autodl-tmp/dataset/datasets_train')\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'response_total', 'response'],\n",
       "    num_rows: 36869\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset = Dataset.load_from_disk('autodl-tmp/dataset/datasets_val')\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2TokenizerFast(name_or_path='autodl-tmp/qwen/Qwen2-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('autodl-tmp/qwen/Qwen2-7B-Instruct', trust_remote_code=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lst = [\n",
    "            \"你是一个语义分类器。\",\n",
    "            \"你将扮演一个文本意图识别器。\",\n",
    "            \"你的功能是识别用户输入的语义类别。\",\n",
    "            \"你的任务是将文本分配到相应的类别中。\",\n",
    "            \"请将自己视为一个文本分类专家。\",\n",
    "            \"你的目标是理解并分类文本的意图。\",\n",
    "            \"你能够识别和归类不同的文本主题。\",\n",
    "            \"你在这里是为了将文本信息分门别类。\",\n",
    "            \"你的角色是文本意图的分类器。\",\n",
    "            \"你是一个专业的语义识别系统。\",\n",
    "            \"你专注于文本的语义分析和分类。\",\n",
    "            \"你将提供文本意图的分类服务。\",\n",
    "            \"你致力于精确地识别和分类文本内容。\",\n",
    "            \"你的任务是分析文本并将其归入适当的类别。\",\n",
    "            \"你将帮助识别文本的语义范畴。\",\n",
    "            \"你能够快速地对文本进行语义分类。\",\n",
    "            \"你的任务是将文本意图进行精确分类。\",\n",
    "            \"你是文本语义分类助手。\",\n",
    "            \"你将确保文本被正确地分类到其语义类别中。\",\n",
    "            \"你的角色是确保文本分类的准确性和效率。\",\n",
    "            \"你能为文本提供深入的语义分析和分类。\"]  #len = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_lst = [\n",
    "    \"A正面，B负面，C中性，D讽刺，E无产品评价语意\",\n",
    "    \"A积极评价，B消极评价，C中立态度，D反讽意味，E无关产品评价的语境\",\n",
    "    \"A正面反馈，B负面反馈，C中立观点，D讽刺语气，E非产品评价内容\",\n",
    "    \"A正面情绪，B负面情绪，C无明显倾向，D讽刺性表达，E非评价性语义\",\n",
    "    \"A赞赏性，B批评性，C客观性，D嘲讽性，E非评价性语义\",\n",
    "    \"A正面评价倾向，B负面评价倾向，C评价中立，D讽刺性语气，E非评价性语境\",\n",
    "    \"A积极情绪表达，B消极情绪表达，C情绪中性，D讽刺性语调，E非产品评价语义\",\n",
    "    \"A正面情感色彩，B负面情感色彩，C情感中立，D讽刺性语气，E非评价性语义\",\n",
    "    \"A正面评价，B负面评价，C评价中立，D讽刺性表达，E非产品评价语义\",\n",
    "    \"A积极评价倾向，B消极评价倾向，C评价中性，D讽刺性语气，E非评价性语境\",\n",
    "    \"A正面情感，B负面情感，C情感中立，D讽刺性语调，E非评价性语义\",\n",
    "    \"A正面评价语境，B负面评价语境，C中立评价语境，D讽刺性语境，E非评价性语境\",\n",
    "    \"A积极情绪倾向，B消极情绪倾向，C情绪中立，D讽刺性语气，E非产品评价语境\",\n",
    "    \"A正面评价性质，B负面评价性质，C评价性质中立，D讽刺性质，E非评价性质\",\n",
    "    \"A正面评价特征，B负面评价特征，C评价特征中立，D讽刺特征，E非评价特征\",\n",
    "    \"A积极评价语义，B消极评价语义，C评价语义中立，D讽刺语义，E非评价语义\",\n",
    "    \"A正面情感倾向性，B负面情感倾向性，C情感倾向性中立，D讽刺倾向性，E非评价倾向性\",\n",
    "    \"A正面评价语义特征，B负面评价语义特征，C评价语义中立，D讽刺语义特征，E非评价语义特征\",\n",
    "    \"A正面评价语境特征，B负面评价语境特征，C评价语境中立，D讽刺语境特征，E非评价语境特征\",\n",
    "    \"A积极评价语义倾向，B消极评价语义倾向，C评价语义中立，D讽刺语义倾向，E非评价语义倾向\",\n",
    "    \"A正面情感语义，B负面情感语义，C情感语义中立，D讽刺情感语义，E非情感评价语义\"]\n",
    "def reflash(x,label):\n",
    "    start = x.find(label)\n",
    "    end = x.find('，',start)\n",
    "    return x[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func_train(example):\n",
    "    MAX_LENGTH = 386\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction_seed = random.randint(0,len(prompt_lst)-1)\n",
    "    select_seed = random.randint(0,15)\n",
    "    instruct = prompt_lst[instruction_seed]\n",
    "    select = response_lst[select_seed]\n",
    "    get_select = example['response'][0]\n",
    "    response_select = reflash(select, get_select)\n",
    "    # 随机替换分类表现选项\n",
    "    instruction = '<|im_start|>user\\n' + instruct + (example['input']).replace(\"\\'\\'\\'\",\"\").replace('简要说明理由','').replace(', \"理由\": \" \"','?') + '<|im_end|>\\n'\n",
    "    instruction = instruction.replace(\"A正面，B负面，C中性，D讽刺，E无产品评价语意\",select)\n",
    "    instruction = tokenizer(instruction, add_special_tokens = False)\n",
    "    \n",
    "    response = tokenizer(f'<|im_start|>assistant\\n\"分类标签\":\"{response_select}\"<|im_end|>\\n' , add_special_tokens = False)\n",
    "    input_ids = instruction['input_ids'] + response['input_ids'] + [tokenizer.eos_token_id]\n",
    "    attention_mask = instruction['attention_mask'] + response['attention_mask'] + [1]\n",
    "    labels = [-100] * len(instruction['input_ids']) + response['input_ids'] + [tokenizer.eos_token_id]\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    \n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func_val(example):\n",
    "    MAX_LENGTH = 386\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction_seed = random.randint(0,len(prompt_lst)-1)\n",
    "    select_seed = random.randint(10,20)\n",
    "    instruct = prompt_lst[instruction_seed]\n",
    "    select = response_lst[select_seed]\n",
    "    get_select = example['response'][0]\n",
    "    response_select = reflash(select, get_select)\n",
    "    # 随机替换分类表现选项\n",
    "    instruction = '<|im_start|>user\\n' + instruct + (example['input']).replace(\"\\'\\'\\'\",\"\").replace('简要说明理由','').replace(', \"理由\": \" \"','?') + '<|im_end|>\\n'\n",
    "    instruction = instruction.replace(\"A正面，B负面，C中性，D讽刺，E无产品评价语意\",select)\n",
    "    instruction = tokenizer(instruction, add_special_tokens = False)\n",
    "    \n",
    "    response = tokenizer(f'<|im_start|>assistant\\n\"分类标签\":\"{response_select}\"<|im_end|>\\n' , add_special_tokens = False)\n",
    "    input_ids = instruction['input_ids'] + response['input_ids'] + [tokenizer.eos_token_id]\n",
    "    attention_mask = instruction['attention_mask'] + response['attention_mask'] + [1]\n",
    "    labels = [-100] * len(instruction['input_ids']) + response['input_ids'] + [tokenizer.eos_token_id]\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    \n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_train = train_dataset.map(process_func_train, remove_columns=train_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_shuffle = tokenized_train.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be5695e77434975bc0513b1cc5b741e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 36869\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_val = val_dataset.map(process_func_val, remove_columns=train_dataset.column_names)\n",
    "tokenized_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "你将扮演一个文本意图识别器。#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，# 评论：review = \"手上刚好有盒小字版软金沙。几个指标和网站不一样阿。12　 　 1.2　 　 　 　12。\"# 输出格式： \"分类标签\": \"A正面评价性质，B负面评价性质，C评价性质中立，D讽刺性质，E非评价性质\"?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\"分类标签\":\"B负面评价性质\"<|im_end|>\n",
      "<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_train_shuffle[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>assistant\\n\"分类标签\":\"B负面评价性质\"<|im_end|>\\n<|im_end|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(filter(lambda x: x != -100, tokenized_train_shuffle[0]['labels'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4116389e2349588dcc6740ba15b522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(152064, 3584)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基础模型  16G+\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'autodl-tmp/qwen/Qwen2-7B',\n",
    "    device_map='auto',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # cache_dir=cache_dir,\n",
    "    # quantization_config=nf4_config,\n",
    "    # low_cpu_mem_usage = True\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开启检查点\n",
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=8, target_modules={'q_proj', 'down_proj', 'k_proj', 'o_proj', 'up_proj', 'gate_proj', 'v_proj'}, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    target_modules = ['q_proj','k_proj','v_proj','o_proj','gate_proj','up_proj','down_proj'],\n",
    "    inference_mode = False,\n",
    "    r = 8,\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0.1\n",
    "                            )\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='autodl-tmp/qwen/Qwen2-7B', revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=8, target_modules={'q_proj', 'down_proj', 'k_proj', 'o_proj', 'up_proj', 'gate_proj', 'v_proj'}, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model = get_peft_model(model,config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 20,185,088 || all params: 7,635,801,600 || trainable%: 0.26434798934534914\n"
     ]
    }
   ],
   "source": [
    "# 可训练参数\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='autodl-tmp/peft/lora_f16',\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True,\n",
    "    # shuffle=True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train_shuffle,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6960' max='6960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6960/6960 4:44:24, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.092800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.033700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.030900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.029800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-100 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-200 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-300 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-400 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-600 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-700 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-800 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-900 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-1100 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-1200 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-1300 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-1400 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-1600 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-1700 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-1800 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory autodl-tmp/peft/lora_f16/checkpoint-1900 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6960, training_loss=0.022500848016519658, metrics={'train_runtime': 17067.3448, 'train_samples_per_second': 6.525, 'train_steps_per_second': 0.408, 'total_flos': 7.122248395331328e+17, 'train_loss': 0.022500848016519658, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('autodl-tmp/peft/lora16/tokenizer_config.json',\n",
       " 'autodl-tmp/peft/lora16/special_tokens_map.json',\n",
       " 'autodl-tmp/peft/lora16/vocab.json',\n",
       " 'autodl-tmp/peft/lora16/merges.txt',\n",
       " 'autodl-tmp/peft/lora16/added_tokens.json',\n",
       " 'autodl-tmp/peft/lora16/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_path = 'autodl-tmp/peft/lora16'\n",
    "trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained('peft_model_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained('peft_model_path1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=False,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = prepare_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str1 = eval(data.iloc[0].system)['content']\n",
    "# str2 = eval(data.iloc[0].user1)['content']\n",
    "# s = str1 + str2\n",
    "# prompt = s\n",
    "# prompt = s\n",
    "messages = [\n",
    "   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": train_dataset[0]['input']}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：review = \"比五星红杉树要好抽\\xa0一点，有点苏烟的味道\"# 输出格式： \"分类标签\": \"A正面，B负面，C中性，D讽刺，E无产品评价语意\", \"理由\": \" \"<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [56568, 101909, 72881, 64559, 70538, 31548, 43326, 88802, 5122, 87752, 106273, 100199, 99752, 104703, 85641, 3837, 101892, 70538, 105151, 43815, 72881, 64559, 71817, 103964, 3837, 2, 220, 85641, 5122, 19417, 284, 330, 56006, 110937, 99425, 103268, 99613, 30534, 52801, 99950, 4102, 100380, 3837, 104037, 99908, 99752, 107254, 57676, 70568, 68805, 5122, 330, 70538, 105151, 788, 330, 32, 106557, 3837, 33, 103276, 3837, 34, 15946, 33071, 3837, 35, 115469, 3837, 36, 42192, 82700, 103964, 72881, 36589, 43869], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data.iloc[0]\n",
    "instruction = '<|im_start|>user\\n' + (eval(example['system'])['content'] + eval(example['user1'])['content']).replace(\"\\'\\'\\'\",\"\").replace('简要说明理由','').replace(', \"理由\": \" \"','?') + '<|im_end|>\\n'\n",
    "\n",
    "instruction = tokenizer(instruction, add_special_tokens = False)\n",
    "response = tokenizer('\\n' + example['output'], add_special_tokens = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你是一个语义分类器.#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，# 评论：review = \"比五星红杉树要好抽\\xa0一点，有点苏烟的味道\"# 输出格式： \"分类标签\": \"A正面，B负面，C中性，D讽刺，E无产品评价语意\"?'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(instruction['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "你是一个语义分类器.#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：review = \"比五星红杉树要好抽 一点，有点苏烟的味道\"# 输出格式：''' \"分类标签\": \"A正面，B负面，C中性，D讽刺，E无产品评价语意\", \"理由\": \" \"<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    37123.000000\n",
       "mean       302.579237\n",
       "std         61.629622\n",
       "min        177.000000\n",
       "50%        293.000000\n",
       "99.9%      697.878000\n",
       "max       1221.000000\n",
       "Name: total_tokens, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['total_tokens'].describe([0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Random.randint() missing 1 required positional argument: 'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Random.randint() missing 1 required positional argument: 'b'"
     ]
    }
   ],
   "source": [
    "random.randint(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchs = []\n",
    "for i in range(len(data)):\n",
    "    str1 = eval(data.iloc[i].system)['content']\n",
    "    str2 = eval(data.iloc[i].user1)['content']\n",
    "    s = str1 + str2\n",
    "    prompt = s\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    batchs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors='pt'\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n",
       "         151645,    198, 151644,    872,    198,  56568, 101909,  72881,  64559,\n",
       "          70538,  31548,  43326,  88802,   5122,  87752, 106273, 100199,  99752,\n",
       "         104703,  85641,   3837, 101892,  70538, 105151,  43815,  72881,  64559,\n",
       "          71817, 103964,   3837,  98237,  30534,  66394, 102401,      2,    220,\n",
       "          85641,   5122,  19417,    284,    330,  56006, 110937,  99425, 103268,\n",
       "          99613,  30534,  52801,  99950,   4102, 100380,   3837, 104037,  99908,\n",
       "          99752, 107254,  57676,  70568,  68805,   5122,  18788,    330,  70538,\n",
       "         105151,    788,    330,     32, 106557,   3837,     33, 103276,   3837,\n",
       "             34,  15946,  33071,   3837,     35, 115469,   3837,     36,  42192,\n",
       "          82700, 103964,  72881,  36589,    497,    330, 102401,    788,    330,\n",
       "            330, 151645,    198, 151644,  77091,    198]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_dataset = data[['system','user1','assistant1','answer2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_dataset.columns = ['instruction','input','response_total','response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(x):\n",
    "    return eval(x)['content'].replace('\\'\\'\\'','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1431/3008227810.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_for_dataset['response_total'] = data_for_dataset['response_total'].map(format)\n"
     ]
    }
   ],
   "source": [
    "data_for_dataset['response_total'] = data_for_dataset['response_total'].map(format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>response_total</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>你是一个语义分类器.</td>\n",
       "      <td>#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...</td>\n",
       "      <td>\"分类标签\": \"B负面\",\"理由\": \"评论中的词汇'太难抽'、'又苦又涩'表达了消费者对...</td>\n",
       "      <td>B负面</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>你是一个语义分类器.</td>\n",
       "      <td>#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...</td>\n",
       "      <td>\"分类标签\": \"B负面\",\"理由\": \"评论中明确指出产品的味道不好，性价比低，这些都是直...</td>\n",
       "      <td>B负面</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>你是一个语义分类器.</td>\n",
       "      <td>#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...</td>\n",
       "      <td>\"分类标签\": \"B负面\",\"理由\": \"评论中明确表达了对于产品的不满，'没咖啡味，不好抽...</td>\n",
       "      <td>B负面</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>你是一个语义分类器.</td>\n",
       "      <td>#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...</td>\n",
       "      <td>\"分类标签\": \"B负面\",\"理由\": \"评论中明确表示了对产品的不满，提到了‘毫无咖啡味’...</td>\n",
       "      <td>B负面</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>你是一个语义分类器.</td>\n",
       "      <td>#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...</td>\n",
       "      <td>\"分类标签\": \"B负面\",\"理由\": \"评论中的“太TM难抽了”表达了强烈的负面情绪，'T...</td>\n",
       "      <td>B负面</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36864</th>\n",
       "      <td>你是一个语义分类器.</td>\n",
       "      <td>#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...</td>\n",
       "      <td>\"分类标签\": \"A正面\",\"理由\": \"评论者对于卷烟产品的描述带有明显的怀旧情感，提到了...</td>\n",
       "      <td>A正面</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36865</th>\n",
       "      <td>你是一个语义分类器.</td>\n",
       "      <td>#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...</td>\n",
       "      <td>\"分类标签\": \"A正面\",\"理由\": \"评论中提到‘特别好抽’，并且将产品与同等价位的其他...</td>\n",
       "      <td>A正面</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36866</th>\n",
       "      <td>你是一个语义分类器.</td>\n",
       "      <td>#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...</td>\n",
       "      <td>\"分类标签\": \"A正面\",\"理由\": \"评论中提到‘太想念这个味道了’和‘太棒了’，明显表...</td>\n",
       "      <td>A正面</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36867</th>\n",
       "      <td>你是一个语义分类器.</td>\n",
       "      <td>#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...</td>\n",
       "      <td>\"分类标签\": \"B负面\",\"理由\": \"评论中提到了‘比硬中华劲大’，这通常意味着香烟的口...</td>\n",
       "      <td>C中性</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36868</th>\n",
       "      <td>你是一个语义分类器.</td>\n",
       "      <td>#任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...</td>\n",
       "      <td>\"分类标签\": \"A正面\",\"理由\": \"‘兰花香’一般用来形容卷烟的香味，给人以美好的联想...</td>\n",
       "      <td>A正面</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36869 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      instruction                                              input  \\\n",
       "0      你是一个语义分类器.  #任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...   \n",
       "1      你是一个语义分类器.  #任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...   \n",
       "2      你是一个语义分类器.  #任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...   \n",
       "3      你是一个语义分类器.  #任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...   \n",
       "4      你是一个语义分类器.  #任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...   \n",
       "...           ...                                                ...   \n",
       "36864  你是一个语义分类器.  #任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...   \n",
       "36865  你是一个语义分类器.  #任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...   \n",
       "36866  你是一个语义分类器.  #任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...   \n",
       "36867  你是一个语义分类器.  #任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...   \n",
       "36868  你是一个语义分类器.  #任务：以下是对卷烟产品的评论，按照分类标签内容语义进行评价，简要说明理由# 评论：revi...   \n",
       "\n",
       "                                          response_total response  \n",
       "0      \"分类标签\": \"B负面\",\"理由\": \"评论中的词汇'太难抽'、'又苦又涩'表达了消费者对...      B负面  \n",
       "1      \"分类标签\": \"B负面\",\"理由\": \"评论中明确指出产品的味道不好，性价比低，这些都是直...      B负面  \n",
       "2      \"分类标签\": \"B负面\",\"理由\": \"评论中明确表达了对于产品的不满，'没咖啡味，不好抽...      B负面  \n",
       "3      \"分类标签\": \"B负面\",\"理由\": \"评论中明确表示了对产品的不满，提到了‘毫无咖啡味’...      B负面  \n",
       "4      \"分类标签\": \"B负面\",\"理由\": \"评论中的“太TM难抽了”表达了强烈的负面情绪，'T...      B负面  \n",
       "...                                                  ...      ...  \n",
       "36864  \"分类标签\": \"A正面\",\"理由\": \"评论者对于卷烟产品的描述带有明显的怀旧情感，提到了...      A正面  \n",
       "36865  \"分类标签\": \"A正面\",\"理由\": \"评论中提到‘特别好抽’，并且将产品与同等价位的其他...      A正面  \n",
       "36866  \"分类标签\": \"A正面\",\"理由\": \"评论中提到‘太想念这个味道了’和‘太棒了’，明显表...      A正面  \n",
       "36867  \"分类标签\": \"B负面\",\"理由\": \"评论中提到了‘比硬中华劲大’，这通常意味着香烟的口...      C中性  \n",
       "36868  \"分类标签\": \"A正面\",\"理由\": \"‘兰花香’一般用来形容卷烟的香味，给人以美好的联想...      A正面  \n",
       "\n",
       "[36869 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(data_for_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = Dataset.from_pandas(data_for_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea5031b62c54fe6b3cd5efe90884dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/36869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_data.save_to_disk('./autodl-tmp/dataset/datasets_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'response_total', 'response'],\n",
       "    num_rows: 36869\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.load_from_disk('./autodl-tmp/dataset/datasets_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
